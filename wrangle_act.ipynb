{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 0,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "# Project: Wrangling and Analyze Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering\n",
    "In the cell below, gather **all** three pieces of data for this project and load them in the notebook. **Note:** the methods required to gather each data are different.\n",
    "1. Directly download the WeRateDogs Twitter archive data (twitter_archive_enhanced.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "# importing the necesary modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import requests\n",
    "from IPython.display import Image\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import json\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the twitter_archive_enhanced.csv data with pandas\n",
    "twitter_archive = pd.read_csv('twitter-archive-enhanced.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use the Requests library to download the tweet image prediction (image_predictions.tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using requests module to download twitter-archive-enhanced.csv programatically\n",
    "url = ' https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "response = requests.get(url)\n",
    "with open('image-predictions.tsv', mode='wb') as file:\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Use the Tweepy library to query additional data via the Twitter API (tweet_json.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Twitter API for each tweet in the Twitter archive and save JSON in a text file\n",
    "# These are hidden to comply with Twitter's API terms and conditions\n",
    "consumer_key = 'HIDDEN'\n",
    "consumer_secret = 'HIDDEN'\n",
    "access_token = 'HIDDEN'\n",
    "access_secret = 'HIDDEN'\n",
    "\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "# NOTE TO STUDENT WITH MOBILE VERIFICATION ISSUES:\n",
    "# df_1 is a DataFrame with the twitter_archive_enhanced.csv file. You may have to\n",
    "# change line 17 to match the name of your DataFrame with twitter_archive_enhanced.csv\n",
    "# NOTE TO REVIEWER: this student had mobile verification issues so the following\n",
    "# Twitter API code was sent to this student from a Udacity instructor\n",
    "# Tweet IDs for which to gather additional data via Twitter's API\n",
    "tweet_ids = twitter_archive.tweet_id.values\n",
    "len(tweet_ids)\n",
    "\n",
    "# Query Twitter's API for JSON data for each tweet ID in the Twitter archive\n",
    "count = 0\n",
    "fails_dict = {}\n",
    "start = timer()\n",
    "# Save each tweet's returned JSON as a new line in a .txt file\n",
    "with open('tweet_json.txt', 'w') as outfile:\n",
    "    # This loop will likely take 20-30 minutes to run because of Twitter's rate limit\n",
    "    for tweet_id in tweet_ids:\n",
    "        count += 1\n",
    "        print(str(count) + \": \" + str(tweet_id))\n",
    "        try:\n",
    "            tweet = api.get_status(tweet_id, tweet_mode='extended')\n",
    "            print(\"Success\")\n",
    "            json.dump(tweet._json, outfile)\n",
    "            outfile.write('\\n')\n",
    "        except tweepy.TweepError as e:\n",
    "            print(\"Fail\")\n",
    "            fails_dict[tweet_id] = e\n",
    "            pass\n",
    "end = timer()\n",
    "print(end - start)\n",
    "print(fails_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the text files in the tweet_json.txt into dataframe\n",
    "df_2_list = []\n",
    "with open('tweet_json.txt', encoding='utf-8') as file:\n",
    "    for line in file: \n",
    "        new_data = json.loads(line)\n",
    "        tweet_id = new_data['id']\n",
    "        retweet_count = new_data['retweet_count']\n",
    "        favorite_count = new_data['favorite_count']\n",
    "        df_2_list.append({\n",
    "            'tweet_id': tweet_id,\n",
    "            'retweet_count': retweet_count,\n",
    "            'favorite_count': favorite_count\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the dataframe from the df_2_list text\n",
    "tweet_data_df = pd.DataFrame(df_2_list, columns=['tweet_id', 'retweet_count', 'favorite_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving data to csv\n",
    "tweet_data_df.to_csv('tweet_data_df', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 28,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Assessing Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# displaying the entries and data types of the fields in twitter_archive data\n",
    "twitter_archive.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# displaying the general statistics of the rating_numerators column\n",
    "twitter_archive.rating_numerator.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the rating_numerators which are less than 10\n",
    "twitter_archive[twitter_archive.rating_numerator <10].count()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking ids which have numerators less than 10\n",
    "twitter_archive[twitter_archive.rating_numerator < 10].tweet_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking rating numerator for tweet id 666020888022790149\n",
    "twitter_archive.loc[(twitter_archive.tweet_id == 666020888022790149), 'rating_numerator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general statistics for the denominators\n",
    "twitter_archive.rating_denominator.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweet with the zero denominators\n",
    "twitter_archive[twitter_archive.rating_denominator == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive.name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive[twitter_archive.rating_denominator < 10].count()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive[twitter_archive.rating_denominator != 10].count()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the image-predictions.tsv data with pandas\n",
    "df_image_preditions = pd.read_csv('image-predictions.tsv', sep='\\t')\n",
    "df_image_preditions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_preditions.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# displaying some of these images to see if they are dog images\n",
    "url = df_image_preditions.loc[1840, 'jpg_url']\n",
    "Image(url=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_preditions.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality issues\n",
    "1. Some dog names such as a is not valid and should be name\n",
    "\n",
    "2. Tweet_id should be intergers instead of string\n",
    "\n",
    "3. Time stamp should be date datatype instead of string\n",
    "\n",
    "4. Retweeted_status_id indicates 181 retweet\n",
    "\n",
    "5. There are 440 rating nmerator less than 10\n",
    "\n",
    "6. tweet_id 835246439529840640 has 0 denominators\n",
    "\n",
    "7. missing values for retweet_counts\n",
    "\n",
    "8. Missing photos of some tweet images url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 7,
        "hidden": false,
        "row": 40,
        "width": 12
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "### Tidiness issues\n",
    "1. The dog stage data is separated into four distinct columns\n",
    "\n",
    "2. All the data is related but is devided into three separate dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 32,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make copies of original pieces of data\n",
    "clean_tweet_data_df = tweet_data_df.copy()\n",
    "clean_twitter_archive = twitter_archive.copy()\n",
    "clean_df_image_preditions = df_image_preditions.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #1: Some dog names such as a is not valid and should be name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define:\n",
    "- convert invalid dog name that is NaN or string with lower case laters and extract the correct name from the text columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting None values with appropriate names\n",
    "# and checking if the values have been chnaged\n",
    "clean_twitter_archive.name =clean_twitter_archive.name.replace(regex=['^[a-z]+', 'None'], value=np.nan)\n",
    "sum(clean_twitter_archive.name.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare a function to return names from text column and return NaN if theirs no named word\n",
    "def name(text):\n",
    "    list_text = text.split()\n",
    "    for word in list_text:\n",
    "        if word.lower() == 'named':\n",
    "            name_of_index = list_text.index(word) + 1\n",
    "            return list_text[name_of_index]\n",
    "        else:\n",
    "            pass\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(clean_twitter_archive.name.isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #2: Tweet_id should be intergers instead of string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "source": [
    "#### Define\n",
    "- converting tweet_id tostring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting tweet_id dtypes to string\n",
    "clean_twitter_archive.tweet_id = clean_twitter_archive.tweet_id.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_twitter_archive.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #3: Retweeted_status_id indicates 181 retweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "- delete retweet related rows and columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_twitter_archive = clean_twitter_archive[clean_twitter_archive.retweeted_status_id.isnull()]\n",
    "clean_twitter_archive.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_twitter_archive = clean_twitter_archive.drop(columns=['retweeted_status_id','retweeted_status_user_id','retweeted_status_timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_twitter_archive.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #4: missing values for retweet_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "- already deleted while cleaning previous data issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sum(clean_twitter_archive.retweeted_status_timestamp.isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #5: Missing photos of some tweet images url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "- delete rows with the missig values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_twitter_archive = clean_twitter_archive[clean_twitter_archive.expanded_urls.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_twitter_archive.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #6: The dog stage data is separated into four distinct columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "- Marging the 4 column into one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the stage of the dog from the text column into the new dog_stage column\n",
    "clean_twitter_archive['dog_stage'] = clean_twitter_archive['text'].str.extract('(pupper|floofer|puppo|doggo)')\n",
    "clean_twitter_archive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop some columns pupper|floofer|puppo|doggo\n",
    "clean_twitter_archive = clean_twitter_archive.drop(columns=['pupper', 'floofer', 'puppo', 'doggo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_twitter_archive.dog_stage.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #7: All the data is related but is devided into three separate dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "- maging all the data frame into one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maging the tweeter achive data and the data from the tweepy api\n",
    "# maging the result with the tweeter image prediction data\n",
    "clean_twitter_archive = pd.merge(clean_twitter_archive, clean_tweet_data_df, on=tweet_id, how='left')\n",
    "clean_twitter_archive = pd.merge(clean_twitter_archive, clean_df_image_preditions, on=tweet_id, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_twitter_archive.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing Data\n",
    "Save gathered, assessed, and cleaned master dataset to a CSV file named \"twitter_archive_master.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_twitter_archive.to_csv('twitter_archive_master.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing and Visualizing Data\n",
    "In this section, analyze and visualize your wrangled data. You must produce at least **three (3) insights and one (1) visualization.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# persentage of dog stages visualization\n",
    "dog_stages_df = clean_twitter_archive.dog_stage.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_stages_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pie(dog_stages_df, labels=['pupper', 'doggo', 'puppo', 'floofer'])\n",
    "plt.title('The percentage of dogs stages')\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights:\n",
    "1. pupper has the highest percentage\n",
    "\n",
    "2. floofer has the lowest percentage\n",
    "\n",
    "3. doggo has the second largest percentage"
   ]
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "report_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 10,
      "defaultCellHeight": 20,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
